{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from WindowGen import WindowGenerator\n",
    "import NN_net as nn\n",
    "import utils as utls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_file_train = 3\n",
    "n_input, n_output = 18, 6\n",
    "titels = [\"LPG\",\"LN\",\"HN\",\"LCO\",\"Ffg\",\"Slurry\",\"overall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(num_file_train):\n",
    "    path =  \"./Data/Train_Data_{:n}.xlsx\".format(i+1)\n",
    "    df = pd.read_excel(path)\n",
    "    frames.append(df)\n",
    "\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = utls.trnsfrm(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_clmns, lbl_clmns = utls.get_key(data.columns.to_list(),n_input,n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = WindowGenerator(\n",
    "    label_width=20,\n",
    "    input_width=60,\n",
    "    feature_columns= ftr_clmns+lbl_clmns,\n",
    "    label_columns= lbl_clmns,\n",
    "    shift=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = len(data)\n",
    "train_df = data_t[0 : int(sz*0.7)]\n",
    "val_df = data_t[int(sz*0.7) : int(sz*0.9)]\n",
    "test_df = data_t[int(sz*0.9) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets from the dataframes\n",
    "x_train_t, y_train_t = window.create_dataset(train_df)\n",
    "x_val_t, y_val_t = window.create_dataset(val_df)\n",
    "x_test_t, y_test_t = window.create_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t = x_train_t[:,:,:n_input]\n",
    "x_val_t = x_val_t[:,:,:n_input]\n",
    "yHis = x_test_t[:,:,n_input:]\n",
    "x_test_t = x_test_t[:,:,:n_input]\n",
    "yTrue = utls.invrs_trnsfrm(y_test_t,data,lbl_clmns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHis = utls.invrs_trnsfrm(yHis,data,lbl_clmns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_metrics = {}\n",
    "n_trainable_params = {}\n",
    "history_set = {}\n",
    "times_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.dense_model(window=window, units=5)\n",
    "model_n = \"Dense\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)  \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.conv_flex_model(window=window, filters=3,kernel_size=2)\n",
    "model_n = \"CNN\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)  \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.LSTM_model(0,0,27,4.5e-3,True,0.1, window)\n",
    "model_n = \"LSTM\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n,lr=1e-4,patience_r=30)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)  \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Stacked_LSTM_model(0,0,9,4.5e-3,True,1,window)\n",
    "model_n = \"Stacked-LSTM\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n,lr=1e-2)\n",
    "end_time = (time.time() - start_time)/60\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)   \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.LSTM_model_encoder_decoder(window=window, encoder_units=27, decoder_units=27)\n",
    "model_n = \"ED-LSTM\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n,lr=1e-3)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)  \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.CNN_LSTM(0,0,0,0,72,21,2,2,6e-5,True,0.25,window)\n",
    "model_n = \"CNN-LSTM\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n,lr=1e-4)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)   \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.BiLSTM_model(0,0,16,4e-3,True,0.15,2,window)\n",
    "model_n = \"Bi-LSTM\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X=x_train_t, y=y_train_t, val_X=x_val_t, val_y=y_val_t,model_name=model_n,lr=1e-2)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "yPred = model.predict(x_test_t)\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,\n",
    "    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)    \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reac_train = x_train_t[:,:,[0,1,5,6,9,10,12]]\n",
    "reg_train = x_train_t[:,:,[2,3,4,8,11,13]]\n",
    "frac_train = x_train_t[:,:,[7,14,15,16,17]]\n",
    "\n",
    "reac_val = x_val_t[:,:,[0,1,5,6,9,10,12]]\n",
    "reg_val = x_val_t[:,:,[2,3,4,8,11,13]]\n",
    "frac_val = x_val_t[:,:,[7,14,15,16,17]]\n",
    "\n",
    "reac_test = x_test_t[:,:,[0,1,5,6,9,10,12]]\n",
    "reg_test = x_test_t[:,:,[2,3,4,8,11,13]]\n",
    "frac_test = x_test_t[:,:,[7,14,15,16,17]]\n",
    "\n",
    "n_reac = reac_train.shape[2]\n",
    "n_reg = reg_train.shape[2]\n",
    "n_frac = frac_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.MHNN(window=window,n_reac=n_reac,n_reg=n_reg,n_frac=n_frac)\n",
    "model_n = \"MH-LSTM\"\n",
    "\n",
    "start_time = time.time()\n",
    "history = nn.compile_and_fit(\n",
    "    model, X={\"reac\": reac_train, \"reg\": reg_train, \"frac\": frac_train},\n",
    "    y={\"fccu\": y_train_t},\n",
    "    val_X={\"reac\": reac_val, \"reg\": reg_val, \"frac\": frac_val},\n",
    "    val_y={\"fccu\": y_val_t},\n",
    "    model_name=model_n,lr=1e-3)\n",
    "end_time = (time.time() - start_time)/60\n",
    "\n",
    "yPred = model.predict({\"reac\": reac_test, \"reg\": reg_test, \"frac\": frac_test})\n",
    "\n",
    "t = utls.evaluate_forecast(\n",
    "    y_test_t,\n",
    "    yPred,\n",
    "    n_output,\n",
    "    titels,    model_n,\n",
    "    model)\n",
    "head = [\"Output\", \"mse\", \"mae\", \"mape\", \"r2\"]\n",
    "pd.DataFrame(t).to_excel(\"./\"+model_n+'/err_metrics.xlsx',index=False,header=head)  \n",
    "test_set_metrics[model_n] = t\n",
    "history_set[model_n] = history\n",
    "times_set[model_n] = end_time\n",
    "n_trainable_params[model_n] = np.sum([np.prod(v.shape) for v in model.trainable_variables])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = model.predict({\"reac\": reac_test, \"reg\": reg_test, \"frac\": frac_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_forecast(yHis,yTrue,yPred,window,lbl_clmns,data,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPred = utls.invrs_trnsfrm(yPred, data, lbl_clmns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslts_radar(yTrue,yPred,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utls.plot_rslt_r2_metrics(t,lbl_clmns,model_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (18, 10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "fz = 18\n",
    "x = np.arange(len(test_set_metrics))\n",
    "width = 0.4\n",
    "clr = '#3478b4'\n",
    "ax1.set_ylabel(\"MSE\", fontsize=fz, color=clr)\n",
    "ax1.bar(x- width/2 , [test_set_metrics[i][6][1] for i in test_set_metrics.keys()], width, color=clr)\n",
    "ax1.bar_label(ax1.containers[0],fmt='%.2e', fontsize=12, padding=1)\n",
    "ax1.set_xticks(ticks=x)\n",
    "ax1.set_xticklabels(labels=test_set_metrics.keys(), fontsize=fz)\n",
    "ax1.set_yticklabels(ax1.get_yticks(), fontsize=fz)\n",
    "ax1.xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "clr = '#f57f16'\n",
    "ax2.set_ylabel(\"MAE\", fontsize=fz, color=clr)\n",
    "ax2.bar(x + width/2, [test_set_metrics[i][6][2] for i in test_set_metrics.keys()], width, color=clr)\n",
    "ax2.bar_label(ax2.containers[0],fmt='%.2e', fontsize=12, padding=1)\n",
    "ax2.set_yticklabels(ax2.get_yticks(), fontsize=fz)\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"tst_metrics_e\" +'.svg', dpi=300)\n",
    "plt.savefig(\"tst_metrics_e\" +'.eps', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (18, 10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "\n",
    "\n",
    "fig, ax3 = plt.subplots()\n",
    "\n",
    "x = np.arange(len(test_set_metrics))\n",
    "width = 0.3\n",
    "values = np.arange(0, 1.2, 0.2)\n",
    "clr = '#3478b4'\n",
    "ax3.set_ylabel(\"R² score\", fontsize=fz, color=clr)\n",
    "ax3.bar(x, [test_set_metrics[i][6][-1] for i in test_set_metrics.keys()], width, color=clr)\n",
    "ax3.bar_label(ax3.containers[0],fmt='%.4f', fontsize=12)\n",
    "ax3.set_xticks(ticks=x)\n",
    "ax3.set_xticklabels(labels=test_set_metrics.keys(), fontsize=fz)\n",
    "rounded_values = [round(val, 2) for val in values]\n",
    "ax3.set_yticklabels(rounded_values, fontsize=fz)\n",
    "ax3.xaxis.set_tick_params(rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"tst_metrics_r2\" +'.svg', dpi=300)\n",
    "plt.savefig(\"tst_metrics_r2\" +'.eps', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (18, 10)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "x = np.arange(len(test_set_metrics))\n",
    "width = 0.3\n",
    "\n",
    "clr = '#3478b4'\n",
    "ax1.set_ylabel(\"Computation time\", fontsize=fz, color=clr)\n",
    "ax1.bar(x, [times_set[i] for i in times_set.keys()], width, color=clr)\n",
    "ax1.bar_label(ax1.containers[0],fmt='%.3f', fontsize=12)\n",
    "ax1.set_xticks(ticks=x)\n",
    "ax1.set_xticklabels(labels=test_set_metrics.keys(), fontsize=fz)\n",
    "ax1.xaxis.set_tick_params(rotation=45)\n",
    "ax1.set_yticklabels(ax1.get_yticks(), fontsize=fz)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"train_time\" +'.svg', dpi=300)\n",
    "plt.savefig(\"train_time\" +'.eps', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, sharex=True, figsize=(10, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (key, value) in enumerate(history_set.items()):\n",
    "\n",
    "    axes[i].plot(history_set[key].history[\"loss\"], label=\"train\")\n",
    "    axes[i].plot(history_set[key].history[\"val_loss\"], label=\"validation\")\n",
    "    axes[i].set(title=(key,n_trainable_params[key]))\n",
    "    \n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"train_history\" +'.svg', dpi=fig.dpi)\n",
    "plt.savefig(\"train_history\" +'.eps', dpi=fig.dpi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
